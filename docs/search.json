[
  {
    "objectID": "wk_2_xaringan.html#lidar-radar",
    "href": "wk_2_xaringan.html#lidar-radar",
    "title": "1¬† 2. Portfolio tools: Xaringan and Quarto",
    "section": "1.1 Lidar & Radar",
    "text": "1.1 Lidar & Radar\n\n\n\ntest"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Eunyoung‚Äôs Learning Diary",
    "section": "",
    "text": "Welcome to MY PLACE\nWelcome to Eunyoung‚Äôs diary \nYou might wonder who I am before you explore my learning diary"
  },
  {
    "objectID": "index.html#who-am-i",
    "href": "index.html#who-am-i",
    "title": "Eunyoung‚Äôs Learning Diary",
    "section": "Who am I?",
    "text": "Who am I?\n\nIt is my joy and why I study urban planning: the happiness many people enjoy in their daily lives in the space I created.\nCats save the world \nYes, she is a stray cat Sam-sae-gi in my house that I look after!"
  },
  {
    "objectID": "index.html#my-background-is",
    "href": "index.html#my-background-is",
    "title": "Eunyoung‚Äôs Learning Diary",
    "section": "My background is‚Ä¶",
    "text": "My background is‚Ä¶\n\nMSc., Urban Spatial Science, University College London, U.K.\nB.A., Urban and Regional Planning, Dankook University, Rep.¬†of Korea\n\nI worked as a civil servant in the urban planning area for five years in Korea and also worked in real estate finance. I want to apply the knowledge I have learned in CASA to smart city initiatives and revitalise towns and agriculture in the countryside. (This is why I am taking this module for later üôÇ)"
  },
  {
    "objectID": "index.html#what-i-am-interested-in",
    "href": "index.html#what-i-am-interested-in",
    "title": "Eunyoung‚Äôs Learning Diary",
    "section": "What I am interested in‚Ä¶",
    "text": "What I am interested in‚Ä¶\n\nSmart cities initiative\nRevitalise towns and agriculture in the countryside (This is why I am taking this module for later:D)\n\nOkay, let‚Äôs wrap up my brief introduction here and look around my diary now"
  },
  {
    "objectID": "wk_1_remote_sensing.html#summary",
    "href": "wk_1_remote_sensing.html#summary",
    "title": "1. An Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 Remote sensing üì°\n\nAcquiring information from a distance through sensors such as satellites, planes(aerial imagery), drones etc. - e.g.¬†satellites collect data on the same points on Earth every day to every 16 days.\nType of orbit\n\ngeosynchronous orbit (GSO): satellite matches the Earth‚Äôs rotation\ngeostationary orbit: holds the same position\n\n\n\n\n1.1.2 Types of waves „Ä∞Ô∏è\n\nAn electromagnetic wave has two components, an electric field(moving up and down) and a magnetic field(moving left and right).\n\nThe two types of sensors with electromagnetic waves.\n\n\n\n\n\n\n\n\n\n\nTypes\nHow to work\nEmission\nExamples\n\n\nPassive\nuse available energy\n(from the sun)\nNothing\nHuman eye, camera,\nsatellite sensor\n\n\nActive\nhave an energy source for illumination\nemits electromagnetic waves and then waits to receive\nRadar, X-ray, LiDAR\n\n\n\n\n\n\n\n\n\nSource: Nadhir Al-Ansari\n\n\n\n\n\nElectromagnetic radiation(EMR) from the sun isn‚Äôt automatically reflected. It interacts with Earth‚Äôs surface and chchangesefore hitting the sensor.- e.g.¬†being absorbed by the surface, transmitted through the surface, or (sunlight is) scattered by particles in the atmosphere.\nSunlight\n\nAn electromagnetic wave emitted by the sun.\nThe shorter the wavelength,\n\nthe more robust the electromagnetic wave energy\nthe bluer it is üåà\n\nThe visible colour usually changes depending on the distance light reaches and the size of particles in the atmosphere.\n\n\n\n\n\n\n\n\nTypes\nFeature\n\n\n\n\nVisible light\n\nhas a rainbow spectrum\nParticles or molecules scatter unabsorbed ultraviolet rays in the atmosphere, and we can only observe this.\n\n\n\nInfrared light\n\ninvisible\n\n\n\nUltraviolet light\n\ninvisible\nabsorbed mainly by the ozone layer\n\n\n\n\n\n\n\n\n\n\nSource: NASA\n\n\n\n\n\n\n1.1.3 Light scattering & methods to gauge distance üìê\n\nA phenomenon in which light with straightness is scattered in all directions by rough surfaces or tiny particles.\nIt makes distance measurement difficult (e.g.¬†atmosphere, clouds) ‚Üí we need alternative methods to gauge distance\n\nSynthetic aperture radar (SAR): Polarization, Fluoresence\nBidirectional Reflectance Distribution Function (BRDF): reflects visible and invisible parts simultaneously depending on the satellite angle\nAtmospheric correction: remove what affected by the atmospheric scattering\n\nLow resolution means it has a large pixel size\nFour elements to decide the resolution of Remotely sensed data\n\n\n\n\n\n\n\n\n\nTypes\nFeature\nExamples\n\n\n\n\nSpatial\n\nthe size of the raster grid per pixel\n\n20cm / 30m\n\n\nSpectral\n\nthe number of bands it records data in\n\n-\n\n\nTemporal\n\nthe time it revisits\n\ndaily / weekly / on demand\n\n\nRadiometric\n\nidentify differences in light or reflectance\nlower the radiometric resolution, the lower the quality of the image\n\n4/8/11-bit sensor"
  },
  {
    "objectID": "wk_1_remote_sensing.html#application",
    "href": "wk_1_remote_sensing.html#application",
    "title": "1. An Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\n\nIn forestry: Forest (soil) survey, pest damage investigation, forest fire damage investigation, tree species discrimination (confirming the distribution of coniferous or broadleaf trees) by taking seasonal aerial photographs.\nIn architecture: to crack down on illegal buildings or check the boundaries of buildings / cadastral lines.\nto identify or prevent the degree of damage from natural disasters such as air pollution and floods.\nto check time-series changes in distances or spaces at specific locations.\naerial photographs of famous tourist attractions are interpreted as artwork.\nWhen choosing the most appropriate sensor for the analysis, the following factors should be considered: Size of features, date range, revisit requirement, spectral sensitivity, cost etc."
  },
  {
    "objectID": "wk_1_remote_sensing.html#reflection",
    "href": "wk_1_remote_sensing.html#reflection",
    "title": "1. An Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nI tend to check the location in advance with satellite images through Google Maps before I go to an unfamiliar place.\nLearning about remote sensing data in Week 1 reminded me that I have been unconsciously using tremendously advanced technology so far, and I have not recognised it because it is commonly used. In addition, it also reminded me that I used annual aerial photographs to check the phenomenon of the urban sprawl of Suwon City when I worked in South Korea.\nConsidering that remote sensing data(e.g.¬†aerial photographs) taken at equal intervals can soon be used as historical data for specific spaces, I thought it would be interesting to make future museums fill with 3D aerial photographs, not relics."
  },
  {
    "objectID": "wk_2_xaringan.html",
    "href": "wk_2_xaringan.html",
    "title": "1¬† 2. Remote Sensor: Lidar & Radar",
    "section": "",
    "text": "library(xaringanExtra)\nThis is a learning diary for week 2.\nLet‚Äôs find out about Lidar and Radar!\nTo view this presentation full-screen, click here."
  },
  {
    "objectID": "wk_3_corrections.html#summary",
    "href": "wk_3_corrections.html#summary",
    "title": "3. Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Why does image distortion occur?\n\nSensor orientation (e.g.¬†shadows depend on satellite angle)\nTopographical variation (e.g.¬†hills, mountains)\nWind (if it is taken by a plane)\nRotation of the earth (from satellite)\nCurvature of the earth\nAtmospheric particles (absorption and scattering create the haze)\n\nSo, we need to correct for inaccuracies of images!\n\n\n3.1.2 Types of Correction\n\n3.1.2.1 Geometric correction\n\nUse GCP(Ground Control Point): match known points in the image and a reference dataset\n\n\n\n\n\n\nSource: Abdul Basith\n\n\n\n\n\nResampling (e.g.¬†Nearest Neighbor, Linear, Cubic, Cubic spline)\n\nCorrected Image(black line), Original Image(dotted line)\n\n\n\n\n\n\n\n(a) nearest neighbor, (b) bilinear interpolation, and (c) cubic convolution / Source: Beshoy Nady\n\n\n\n\n\n\n3.1.2.2 Atmospheric correction\n\n\n\n\n\n\n\nTypes\nDetails\n\n\nDark object subtraction(DOS)\nFind the brightest value based on the darkest value (assuming distortion was caused by air because air reflects light)\n\n\nPsuedo-invariant Features (PIFs)\nAdjust the brightness pixels using regression\n\n\nPy6s\nSecond Simulation of the Satellite Signal in the Solar Spectrum(6S), which can now be used through python\n\n\nEmpirical Line Correction\nPath radiance, Atmospheric attenuation\n\n\n\n\n\n3.1.2.3 Orthorectification/Topographic correction\n\nSensor geometry and an elevation model are necessary to use orthorectification correction.\nIt is important to use terrain data with high resolution and accuracy.\nUse Cosine correction with solar azimuth and the angle of local zenith.\n\n\n\n\n\n\nSource: Eric Setyawan\n\n\n\n\n\n\n3.1.2.4 Radiometric calibration\n\nCaptures image brightness and assigns a Digital Number(DN)\nCompare DN with spectral radiance = Radiometric calibration\n\n\n\n\n\n\n\nNote\n\n\n\n[Remote Sensing Jargon] 1. Energy\nWhen the sun‚Äôs radiant energy üåû passes through the Earth‚Äôs atmosphere ‚ò∑ and touches the surface of an object ü™®,\n\nRadiance\n\nThe amount of energy radiated from the object‚Äôs surface.\nAlso includes the amount of energy from the surroundings + the amount of radiation reflected from the clouds above the surface.\n\nIrradiance\n\nThe amount of energy entering the surface of an object.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n[Remote Sensing Jargon] 2. Influencing factors\nAlong the way from the SUN üåû to the sensor üõ∞,\n\nDigital Number\n\nThe intensity of the electromagnetic radiation per pixel.\nPixel values aren‚Äôt calibrated and have no unit.\nTherefore, it is necessary to convert to ‚Äòradiance‚Äô or ‚Äòreflectance‚Äô.\n\nRadiance\n\nRefer to the explanation above.\n\nReflectance\n\nThe ratio of radiation reflected on the surface.\nThe object can be detected by correcting them with reflectivity values (since specific objects can be determined as reflectivity values).\n4 types of reflectance : TOA(Top of Atmosphere), Surface, Hemispherical, Apparent \n\n\n\n\n\n\n\n3.1.3 Joining data sets = Mosaicking\n\nIt feathers the images together and creates a seamless mosaic or image(s)! (Look at the circle)\n\n\n\n\n\n\nSource: WhiteboxDev, stackexchange\n\n\n\n\n\n\n3.1.4 Image Enhancement\n\nImagery can be ‚Äúimproved/enhanced‚Äù based on the energy reflected and the contrast between features.\nThere are many types of image enhancement\n\nPiecewise Linear Contrast Stretch\nRatio: Band ratioing, Normalized Burn Ratio\nFiltering: Using pixels\nPCA: Transform multi-spectral data into uncorrelated and smaller dataset\nTexture : use tonal(spectral) data, not texture(spatial variation of gray values)\nFusion : where data from multiple sensors / sources is fused together"
  },
  {
    "objectID": "wk_3_corrections.html#application",
    "href": "wk_3_corrections.html#application",
    "title": "3. Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\n\nRemote sensing products are now Analysis Ready Data(ARD)! = Corrected data\n\n\n\n\n\n\nSource: Kri≈°tof O≈°tir\n\n\n\n\n\nAccording to the ‚ÄòRegulations for aerial photographic surveying‚Äô notice of the National Geographic Information Institute in South Korea, there are articles related to aerial photography and correction to get aerial photos with clear resolution.\nMonitoring the changes in the national territory with a corrected photo/image is possible.\n\nTake aerial photography by dividing the country into urban areas (12cm resolution, 1-year cycle) and general regions (25cm resolution, 2-year cycle).\nAfter orthogonal processing and colour correction, produce user-specific (civilian and military) orthographic images nationwide.\n\n\n\n\n\n\n\nSource: National Geographic Information Institute in South Korea"
  },
  {
    "objectID": "wk_3_corrections.html#reflection",
    "href": "wk_3_corrections.html#reflection",
    "title": "3. Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nI realised that remote sensing data, which is easily used in everyday life, come to my hands through various pre-processing(correction/calibration). And I also learned that numerous studies, efforts, and multiple methods had been considered until this became possible.\nEspecially for Landsat data, I came to think about the benefits of open-source data in that the frequency of use and data utilization had increased exponentially since October 2008, when the Landsat data was open to the public. The story of Virginia Norwood was also interesting, who came up with the initial idea of Landsat technology.\nIn addition, I also realised it is necessary to consider whether remote sensing data is properly pre-processed and suitable for use before data analysis even though remote sensing data provided these days uses corrected data."
  },
  {
    "objectID": "wk_4_policy.html#summary",
    "href": "wk_4_policy.html#summary",
    "title": "4. Policy: 2025 Jeju Master Plan",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 How is Jeju? üèûÔ∏è\n\nJeju island is a representative tourist city in South Korea.\nIt is divided into residential, commercial, industrial, and conservation land. In conservation land, four Gotjawal areas with unique vegetation are distributed. üå≥üå≤\nVegetation damage and increased Gotjawal erosion have recently occurred due to the construction of cultivated land, various development projects such as golf courses, roads, and visitors.\n\n\n\n\n\n\nSource: Eunyoung\n\n\n\n\n\n\n4.1.2 2025 Jeju Master Plan\n\nCreating an ecological map and building a GIS map\nIntroduction of Total Environmental Resources System\n\nThe development and application of ecological area ratio indicators at the spatial planning level to comprehensively induce the maintenance and improvement of the ecological functions of urban spaces.\nAllow development activities after creating alternative environmental resources in case of environmental damage.\n\nDesignation of ‚ÄòEcological and Scenery Conservation Area‚Äô under the Natural Environment Conservation Act ü¶Ö\nIntroduction of Landscape M.A.¬†(Mater Architect) System and Landscape Advice System\nActive utilisation and management of spatial information by linking preservation ratings (regulating development activities on Jeju island followed by ordinances) with GIS Source: 2025 Jeju Master Plan\n\n\n\n4.1.3 The 5th National Land Comprehensive Plan (2020~2040)\n\n\n\n\n\n\n\nGoal\nA Smart, International City with a clean environment\n\n\n\n\nDetails\nCreating a Global Clean Environment City\n\n\n\n- Introduction of total environmental resources system\n\n\n\n- Establishment of an environment preservation system\n\n\n\nSource: Ministry of Land, Infrastructure and Transport\n\n\n4.1.3 UN SDGs(Sustainable Development Goal 15 )\n\nGoal 15. LIFE ON LAND\n\nBiodiversity and ecosystems\n\nsustainable management of the planet‚Äôs natural resources\nprotect, restore and promote sustainable use of terrestrial ecosystems\ntake urgent and significant action to reduce the degradation of natural habitats\nhalt the loss of biodiversity\n\nForests\n\npromote international policy coordination and cooperation in order to achieve forest management\n\n\n\nSource: UNDP, UN SDGs"
  },
  {
    "objectID": "wk_4_policy.html#application",
    "href": "wk_4_policy.html#application",
    "title": "4. Policy: 2025 Jeju Master Plan",
    "section": "4.2 Application",
    "text": "4.2 Application\n\nIllegal forest activities have recently increased, especially in the Gotjawal area, such as forest damage, prohibited mountainous area exclusive use, illegal access road construction, and unauthorized logging. ü™µü™ì\n\nMonitoring and cracking down on various illegal activities in the forest with aerial photographs using high-resolution drones. üì∏\n\n\n\n\n\n\n\nSource: ChosunBiz\n\n\n\n\n\nThe local government of Jeju is currently establishing a total environmental resources system.\n\n\n\n\n\n\n\nNote\n\n\n\nA Total Environmental Resources System\n\nMaintaining the ratio of total environmental resources before and after developing a specific area on Jeju Island\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Future Plan\n\n\n\n\n\n\n\nYear\nPlan\n\n\n\n\n2023\nRevision and enactment of ordinances and guidelines to establish an organisation and fund for a total environmental resources system\n\n\n2024\nPilot operation of the total environmental resources system\n\n\n2025\nOperation of the total environmental resources system in earnest"
  },
  {
    "objectID": "wk_4_policy.html#reflection",
    "href": "wk_4_policy.html#reflection",
    "title": "4. Policy: 2025 Jeju Master Plan",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\n63% of South Korea is mountainous areas, and it is necessary to preserve excellent natural scenery. Therefore, many local governments in Korea have recently established spatial information systems to utilise for forest preservation and a crackdown on illegal activities, etc.\nAmong them, Jeju Island is a UNESCO-certified nature conservation area. World Natural Heritage Jeju\n\n\n\n\n\n\n\n\n\n2002\n2007\n2010\n\n\n\n\na biosphere reserve\na World Natural Heritage site\na UNESCO Global Geopark\n\n\n\n\nI have worked as a civil servant in Korea, and aerial photographs could not be used as legal proof when cracking down on illegal activities but were only a reference until a few years ago. However, the use of aerial photographs began to be legislated as the importance of using spatial information emerged.\nConsidering the development technology direction of remote sensing data I learned in class so far, the use of spatial information in policy will increase more and more. So, I thought I should also know how to use this information smartly."
  },
  {
    "objectID": "wk_5_GEE.html#summary",
    "href": "wk_5_GEE.html#summary",
    "title": "5. Google Earth Engine(GEE)",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 What is GEE?\n\nA platform tool for analysing geospatial information/datasets provided by Google (e.g.¬†analysis of forest coverage, land use change, or assess the health of agricultural fields) (‚ÄúFAQ  Google Earth Engine,‚Äù n.d.)\nGEE uses Javascript\nGEE has two sides: Client side & Server side\n\nIt has no data in the script (like the data environments in R)\nAny pre-loaded data product will be on the server side\n\nSo we need to use the Map() function instead of for loop!\nLoading the complete image collection is inefficient when we don‚Äôt know what is inside the image collection = The reason why we need to use the ‚ÄòMap()‚Äô function\n\n\nGEE converts all data into the Mercator projection (EPSG:3857) when displayed (also can set the projection manually)\n\n\n\n5.1.2 Image components in GEE\n\n\n\n\n\n\n\nRaster\nan image\n\n\nImage Collection\nseveral images or polygons = a stack of raster data\n\n\n\nSo we use the specific function to load and manipulate it. We can also filter using dates/region/geometry.\n\n\n5.1.3 How to use GEE?\n\n5.1.3.1 Set a band\nIf you want to set Red / Green / Blue visualisation, e.g.¬†bands: [‚ÄòB4‚Äô, ‚ÄòB3‚Äô, ‚ÄòB2‚Äô]\n\n\n5.1.3.2 Set your scale\n\nImage scale in GEE = Pixel resolution set by the output\nWe can analyse our map/image depending on the zoom level(scale)\n\n\n\n\n\n\nWhen you make a request for an image to display or a statistic results, you specify the scale at which data is input to the analysis. / Source: GEE\n\n\n\n\n\n\n\n5.1.4 GEE functions\n\n5.1.4.1 Reducing images\n\nMake one statistically calculated image using multiple satellite images from the Image Collection\n\ncollection.reduce(ee.Reducer.median/mean/min/variance()) : Choose a Reducer parameter you want to use\nreduceRegion() : Reducing images by region (use a polygon)\nreduceRegions() : Reducing images by regions (use a polygons)\nreduceNeighborhood() : Reducing images by neighbourhoods\ncollection.select(['system:time_start','pr_mean']).reduce(ee.Reducer.linearFit()) : Regression (when we want to see the change over time in pixel values)\n\n\n\n\n5.1.4.2 Joins and filtering\n\nJoin image collections (e.g.¬†Satellite data from January with data from October)\nJoin feature collections (e.g.¬†different polygons)\nUse the code ee.Filter()\n\n\n\n5.1.4.3 Mosaicking\n\nCombining multiple images"
  },
  {
    "objectID": "wk_5_GEE.html#application",
    "href": "wk_5_GEE.html#application",
    "title": "5. Google Earth Engine(GEE)",
    "section": "5.2 Application",
    "text": "5.2 Application\nIt is being used for various studies of the global climate, topography, and satellite image data accumulated by Google through GEE, such as surveys on water depletion or the devastation of the Amazon rainforest.\nIn the case of the polar glacier monitoring, we can see that it is the decrease in glacial volume over time, as (Li, Wang, and Wu 2022) mentioned.\n\n\n\n\n\nCareser Glacier changes during the 1986‚Äì2020 period. (a) The newNIR band Landsat images for Careser Glacier in 1986, 1996, 2009 and 2020. (b) Latest Google Earth image for Careser Glacier."
  },
  {
    "objectID": "wk_5_GEE.html#reflection",
    "href": "wk_5_GEE.html#reflection",
    "title": "5. Google Earth Engine(GEE)",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThere are many things to learn in this endless world ü§Ø\nI‚Äôve heard much about GEE before, so it was good to know what GEE is and how to use it through this week‚Äôs lecture. Most of the environmental and glacier photos I usually see in news articles are GEE data, meaning GEE is used often in everyday life.\nI was worried that it would be challenging to use GEE‚Äôs code because it was in Javascript. But I could understand and use it easily as it was similar to Python or R.\nWhen I get used to using GEE, I want to analyze the time series of forest destruction change in Jeju Island through GEE data, which I discussed in the 4th week.\n\n\n\n\n‚ÄúFAQ  Google Earth Engine.‚Äù n.d. https://earthengine.google.com/faq/.\n\n\nLi, Xiang, Ninglian Wang, and Yuwei Wu. 2022. ‚ÄúAutomated Glacier Snow Line Altitude Calculation Method Using Landsat Series Images in the Google Earth Engine Platform.‚Äù Remote Sensing 14 (10): 2377. https://doi.org/10.3390/rs14102377."
  },
  {
    "objectID": "wk_6_classification.html#summary",
    "href": "wk_6_classification.html#summary",
    "title": "6. Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 How do we know? ü§î\nFollow your intuition! We can make judgments or conclusions about specific knowledge from our experience. It is called inductive learning and can be leveraged to analyze remote-sensing images.\n\n\n6.1.2 How does my computer know? ü§ñ\nLike using human knowledge, machine learning methods (Training data 70% : Testing data 30%) based on decision trees are used to be learned how to find specific patterns in remote sensing data so that computers can judge themselves.\n\n\n6.1.3 Different methods of classification\n\n6.1.3.1 Classification trees\n\nClassify data into two or more discrete categories\n\nWe cannot only know the prediction results but also explain why we predicted that.\nOutput variable is categorised such as sex, nationality or position in the company.\nIt is like playing the guessing game ‚ÄòWho am I?‚Äô\n\nWhen creating a decision tree, the final leaves might be a mixture of the categories = impure\n\nNeed to quantify the result with the Gini Impurity\n\nTop-down approach\n\n\n\n\n\n\n\n\n\n\n\n\n6.1.3.2 Regression trees\n\nDecision Tree model with regression\nIt predicts results based on the predictors that best reduces the Sum of the Squared Residuals(SSR). = similar to Gini Impurity\n\nOutput variable is continuous variable such as salary, weight or width.\n\nBottom-up approach\n\n\n\n\n6.1.4 How to prevent overfitting of results?\n\n6.1.4.1 Weakest link pruning\n\nThere are two parameters: depth and node.\nAfter making a large tree (20 is often used) by increasing the depth and nodes, prune the subtree again and select it as a model.\n\n\n\n\n\n\nSource:ML Wiki\n\n\n\n\n\n\n6.1.4.2 Random forest\n\nOne of the ensemble machine learning model.\nGrow loads of random decision trees like a forest!\n\nAll decision trees are grown by randomly extracting sub-datasets.\nBagging : a single data may be selected multiple times as it allows redundancy.\nAnd find the overall value which got more votes based on all the trees.\n\n\n\n\n\n\n\nSource:freeCodeCamp\n\n\n\n\n\n\n\n6.1.5 Three types of Image Classification\n\n\n\n\n\n\n\n\nSupervised Classification\nUnsupervised Classification\nObject-Based Image Analysis\n\n\n\n\nPattern recognition or machine learning\nclustering\nTBC in week 7\n\n\nParametric (normal distribution) : Maximum likelihood\nk-means\n\n\n\nnon parametric (not normal) : Support Vector Machine\nISODATA\n\n\n\n\ncluster busting = masking (removing unsuitable clusters)\n\n\n\n\n\n6.1.5.1 Maximum Likelihood Eastimation (MLE)\n\nLikelihood : To see what probability is in a distribution existing an event or phenomenon\nMLE : Find the maximum likelihood that best describes a given data\nTakes the image(landcover) and assigns pixel to the most probable land cover type.\n\n\n\n6.1.5.2 Support Vector Machine (SVM)\n\nUsed primarily for classification (pattern recognition) and regression analysis\n\n\n\n\n\n\n\nType\nAim\n\n\nExisting classification methods\nminimise error rate\n\n\nSupport Vector Machine (SVM)\nmaximise the space between the two categories\n\n\n\n\n\n\n\n\n\nSource:Lilly Chen\n\n\n\n\n\n\n\n\n\n\nTip With #SVM Hashtag\n\n\n\n#kernel trick #soft margin"
  },
  {
    "objectID": "wk_6_classification.html#application",
    "href": "wk_6_classification.html#application",
    "title": "6. Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\n\nAn example of SVM?"
  },
  {
    "objectID": "wk_6_classification.html#reflection",
    "href": "wk_6_classification.html#reflection",
    "title": "6. Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\n\nThe key to what we learned this week is that each classification method essentially slices the data differently.\nIt was interesting that the ML technique was used to analyse the remote sensing data. In particular, it was amazing that the SVM method separates data using hyperplane, going further from the existing classification methods.\nIt still takes work to fully understand the mathematical principles of each classification method (which makes me feel dizzy every time I learn it üôÑ). However, it was worth remembering that the criteria that we intuitively thought and classified were developed for computers and applied for."
  },
  {
    "objectID": "wk_2_xaringan_embed_code.html",
    "href": "wk_2_xaringan_embed_code.html",
    "title": "1¬† 2. Remote Sensor: Lidar & Radar",
    "section": "",
    "text": "This is a learning diary for week 2.\nLet‚Äôs find out about Lidar and Radar!\n\n\n\n\n\n\n\n\nTo view this presentation full-screen, click here."
  },
  {
    "objectID": "wk_7_classification_2.html#summary",
    "href": "wk_7_classification_2.html#summary",
    "title": "7. Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 What is GEE?\n\n\n\n\n\nCareser Glacier changes during the 1986‚Äì2020 period."
  },
  {
    "objectID": "wk_7_classification_2.html#application",
    "href": "wk_7_classification_2.html#application",
    "title": "7. Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application"
  },
  {
    "objectID": "wk_7_classification_2.html#reflection",
    "href": "wk_7_classification_2.html#reflection",
    "title": "7. Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection"
  },
  {
    "objectID": "index.html#special-thanks-to",
    "href": "index.html#special-thanks-to",
    "title": "Eunyoung‚Äôs Learning Diary",
    "section": "Special thanks to‚Ä¶",
    "text": "Special thanks to‚Ä¶\nDr Andrew Maclachlan, for teaching us this amazing RSCE module! Making my own learning diary every week is the happiest time for me ‚úèÔ∏è\nOkay, let‚Äôs wrap up my brief introduction here and look around my diary now"
  },
  {
    "objectID": "wk_6_classification.html#regression-trees",
    "href": "wk_6_classification.html#regression-trees",
    "title": "6. Classification I",
    "section": "#### 6.1.3.2 Regression trees",
    "text": "#### 6.1.3.2 Regression trees\n- Output variable can be continuous dependent variable such as salary, weight or width.\n\nUse the Sum of the Squared Residuals\nUse the threshold that gives smallest SSR = always the lowest value (to prevent over fitting) = similar to gini impurity *Weakest link pruning\n\n\n6.1.3.3 Random forest\n\nsupervised : Pattern recognition or machine learning / Classifier learns patterns in the data / Parametric (normal distribution) or non parametric (not normal)\nUnSupervised : clustering, k-means, ISODATA, cluster busting\n\n\n\n6.1.3.4 Maximum likelihood\n: based on probability information\n\n\n6.1.3.5 Support Vector Machine (SVM)"
  },
  {
    "objectID": "wk_6_classification.html#support-vector-machine-svm",
    "href": "wk_6_classification.html#support-vector-machine-svm",
    "title": "6. Classification I",
    "section": "#### 6.1.5.2 Support Vector Machine (SVM)",
    "text": "#### 6.1.5.2 Support Vector Machine (SVM)"
  }
]